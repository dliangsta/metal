import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

__weights_dict = dict()

def load_weights(weight_file):
    if weight_file == None:
        return

    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict

class KitModel(nn.Module):

    
    def __init__(self, weight_file):
        super(KitModel, self).__init__()
        global __weights_dict
        __weights_dict = load_weights(weight_file)

        self.conv2d_1 = self.__conv(2, name='conv2d_1', in_channels=3, out_channels=64, kernel_size=(7, 7), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_1 = self.__batch_normalization(2, 'batch_normalization_1', num_features=64, eps=1.1000000085914508e-05, momentum=0.0)
        self.batch_normalization_2 = self.__batch_normalization(2, 'batch_normalization_2', num_features=64, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_2 = self.__conv(2, name='conv2d_2', in_channels=64, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_3 = self.__batch_normalization(2, 'batch_normalization_3', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_3 = self.__conv(2, name='conv2d_3', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_4 = self.__batch_normalization(2, 'batch_normalization_4', num_features=96, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_4 = self.__conv(2, name='conv2d_4', in_channels=96, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_5 = self.__batch_normalization(2, 'batch_normalization_5', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_5 = self.__conv(2, name='conv2d_5', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_6 = self.__batch_normalization(2, 'batch_normalization_6', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_6 = self.__conv(2, name='conv2d_6', in_channels=128, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_7 = self.__batch_normalization(2, 'batch_normalization_7', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_7 = self.__conv(2, name='conv2d_7', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_8 = self.__batch_normalization(2, 'batch_normalization_8', num_features=160, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_8 = self.__conv(2, name='conv2d_8', in_channels=160, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_9 = self.__batch_normalization(2, 'batch_normalization_9', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_9 = self.__conv(2, name='conv2d_9', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_10 = self.__batch_normalization(2, 'batch_normalization_10', num_features=192, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_10 = self.__conv(2, name='conv2d_10', in_channels=192, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_11 = self.__batch_normalization(2, 'batch_normalization_11', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_11 = self.__conv(2, name='conv2d_11', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_12 = self.__batch_normalization(2, 'batch_normalization_12', num_features=224, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_12 = self.__conv(2, name='conv2d_12', in_channels=224, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_13 = self.__batch_normalization(2, 'batch_normalization_13', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_13 = self.__conv(2, name='conv2d_13', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_14 = self.__batch_normalization(2, 'batch_normalization_14', num_features=256, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_14 = self.__conv(2, name='conv2d_14', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_15 = self.__batch_normalization(2, 'batch_normalization_15', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_15 = self.__conv(2, name='conv2d_15', in_channels=128, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_16 = self.__batch_normalization(2, 'batch_normalization_16', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_16 = self.__conv(2, name='conv2d_16', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_17 = self.__batch_normalization(2, 'batch_normalization_17', num_features=160, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_17 = self.__conv(2, name='conv2d_17', in_channels=160, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_18 = self.__batch_normalization(2, 'batch_normalization_18', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_18 = self.__conv(2, name='conv2d_18', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_19 = self.__batch_normalization(2, 'batch_normalization_19', num_features=192, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_19 = self.__conv(2, name='conv2d_19', in_channels=192, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_20 = self.__batch_normalization(2, 'batch_normalization_20', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_20 = self.__conv(2, name='conv2d_20', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_21 = self.__batch_normalization(2, 'batch_normalization_21', num_features=224, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_21 = self.__conv(2, name='conv2d_21', in_channels=224, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_22 = self.__batch_normalization(2, 'batch_normalization_22', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_22 = self.__conv(2, name='conv2d_22', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_23 = self.__batch_normalization(2, 'batch_normalization_23', num_features=256, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_23 = self.__conv(2, name='conv2d_23', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_24 = self.__batch_normalization(2, 'batch_normalization_24', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_24 = self.__conv(2, name='conv2d_24', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_25 = self.__batch_normalization(2, 'batch_normalization_25', num_features=288, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_25 = self.__conv(2, name='conv2d_25', in_channels=288, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_26 = self.__batch_normalization(2, 'batch_normalization_26', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_26 = self.__conv(2, name='conv2d_26', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_27 = self.__batch_normalization(2, 'batch_normalization_27', num_features=320, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_27 = self.__conv(2, name='conv2d_27', in_channels=320, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_28 = self.__batch_normalization(2, 'batch_normalization_28', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_28 = self.__conv(2, name='conv2d_28', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_29 = self.__batch_normalization(2, 'batch_normalization_29', num_features=352, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_29 = self.__conv(2, name='conv2d_29', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_30 = self.__batch_normalization(2, 'batch_normalization_30', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_30 = self.__conv(2, name='conv2d_30', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_31 = self.__batch_normalization(2, 'batch_normalization_31', num_features=384, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_31 = self.__conv(2, name='conv2d_31', in_channels=384, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_32 = self.__batch_normalization(2, 'batch_normalization_32', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_32 = self.__conv(2, name='conv2d_32', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_33 = self.__batch_normalization(2, 'batch_normalization_33', num_features=416, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_33 = self.__conv(2, name='conv2d_33', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_34 = self.__batch_normalization(2, 'batch_normalization_34', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_34 = self.__conv(2, name='conv2d_34', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_35 = self.__batch_normalization(2, 'batch_normalization_35', num_features=448, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_35 = self.__conv(2, name='conv2d_35', in_channels=448, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_36 = self.__batch_normalization(2, 'batch_normalization_36', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_36 = self.__conv(2, name='conv2d_36', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_37 = self.__batch_normalization(2, 'batch_normalization_37', num_features=480, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_37 = self.__conv(2, name='conv2d_37', in_channels=480, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_38 = self.__batch_normalization(2, 'batch_normalization_38', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_38 = self.__conv(2, name='conv2d_38', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_39 = self.__batch_normalization(2, 'batch_normalization_39', num_features=512, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_39 = self.__conv(2, name='conv2d_39', in_channels=512, out_channels=256, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_40 = self.__batch_normalization(2, 'batch_normalization_40', num_features=256, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_40 = self.__conv(2, name='conv2d_40', in_channels=256, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_41 = self.__batch_normalization(2, 'batch_normalization_41', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_41 = self.__conv(2, name='conv2d_41', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_42 = self.__batch_normalization(2, 'batch_normalization_42', num_features=288, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_42 = self.__conv(2, name='conv2d_42', in_channels=288, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_43 = self.__batch_normalization(2, 'batch_normalization_43', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_43 = self.__conv(2, name='conv2d_43', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_44 = self.__batch_normalization(2, 'batch_normalization_44', num_features=320, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_44 = self.__conv(2, name='conv2d_44', in_channels=320, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_45 = self.__batch_normalization(2, 'batch_normalization_45', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_45 = self.__conv(2, name='conv2d_45', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_46 = self.__batch_normalization(2, 'batch_normalization_46', num_features=352, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_46 = self.__conv(2, name='conv2d_46', in_channels=352, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_47 = self.__batch_normalization(2, 'batch_normalization_47', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_47 = self.__conv(2, name='conv2d_47', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_48 = self.__batch_normalization(2, 'batch_normalization_48', num_features=384, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_48 = self.__conv(2, name='conv2d_48', in_channels=384, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_49 = self.__batch_normalization(2, 'batch_normalization_49', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_49 = self.__conv(2, name='conv2d_49', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_50 = self.__batch_normalization(2, 'batch_normalization_50', num_features=416, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_50 = self.__conv(2, name='conv2d_50', in_channels=416, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_51 = self.__batch_normalization(2, 'batch_normalization_51', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_51 = self.__conv(2, name='conv2d_51', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_52 = self.__batch_normalization(2, 'batch_normalization_52', num_features=448, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_52 = self.__conv(2, name='conv2d_52', in_channels=448, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_53 = self.__batch_normalization(2, 'batch_normalization_53', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_53 = self.__conv(2, name='conv2d_53', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_54 = self.__batch_normalization(2, 'batch_normalization_54', num_features=480, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_54 = self.__conv(2, name='conv2d_54', in_channels=480, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_55 = self.__batch_normalization(2, 'batch_normalization_55', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_55 = self.__conv(2, name='conv2d_55', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_56 = self.__batch_normalization(2, 'batch_normalization_56', num_features=512, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_56 = self.__conv(2, name='conv2d_56', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_57 = self.__batch_normalization(2, 'batch_normalization_57', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_57 = self.__conv(2, name='conv2d_57', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_58 = self.__batch_normalization(2, 'batch_normalization_58', num_features=544, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_58 = self.__conv(2, name='conv2d_58', in_channels=544, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_59 = self.__batch_normalization(2, 'batch_normalization_59', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_59 = self.__conv(2, name='conv2d_59', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_60 = self.__batch_normalization(2, 'batch_normalization_60', num_features=576, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_60 = self.__conv(2, name='conv2d_60', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_61 = self.__batch_normalization(2, 'batch_normalization_61', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_61 = self.__conv(2, name='conv2d_61', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_62 = self.__batch_normalization(2, 'batch_normalization_62', num_features=608, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_62 = self.__conv(2, name='conv2d_62', in_channels=608, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_63 = self.__batch_normalization(2, 'batch_normalization_63', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_63 = self.__conv(2, name='conv2d_63', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_64 = self.__batch_normalization(2, 'batch_normalization_64', num_features=640, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_64 = self.__conv(2, name='conv2d_64', in_channels=640, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_65 = self.__batch_normalization(2, 'batch_normalization_65', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_65 = self.__conv(2, name='conv2d_65', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_66 = self.__batch_normalization(2, 'batch_normalization_66', num_features=672, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_66 = self.__conv(2, name='conv2d_66', in_channels=672, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_67 = self.__batch_normalization(2, 'batch_normalization_67', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_67 = self.__conv(2, name='conv2d_67', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_68 = self.__batch_normalization(2, 'batch_normalization_68', num_features=704, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_68 = self.__conv(2, name='conv2d_68', in_channels=704, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_69 = self.__batch_normalization(2, 'batch_normalization_69', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_69 = self.__conv(2, name='conv2d_69', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_70 = self.__batch_normalization(2, 'batch_normalization_70', num_features=736, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_70 = self.__conv(2, name='conv2d_70', in_channels=736, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_71 = self.__batch_normalization(2, 'batch_normalization_71', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_71 = self.__conv(2, name='conv2d_71', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_72 = self.__batch_normalization(2, 'batch_normalization_72', num_features=768, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_72 = self.__conv(2, name='conv2d_72', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_73 = self.__batch_normalization(2, 'batch_normalization_73', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_73 = self.__conv(2, name='conv2d_73', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_74 = self.__batch_normalization(2, 'batch_normalization_74', num_features=800, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_74 = self.__conv(2, name='conv2d_74', in_channels=800, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_75 = self.__batch_normalization(2, 'batch_normalization_75', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_75 = self.__conv(2, name='conv2d_75', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_76 = self.__batch_normalization(2, 'batch_normalization_76', num_features=832, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_76 = self.__conv(2, name='conv2d_76', in_channels=832, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_77 = self.__batch_normalization(2, 'batch_normalization_77', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_77 = self.__conv(2, name='conv2d_77', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_78 = self.__batch_normalization(2, 'batch_normalization_78', num_features=864, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_78 = self.__conv(2, name='conv2d_78', in_channels=864, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_79 = self.__batch_normalization(2, 'batch_normalization_79', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_79 = self.__conv(2, name='conv2d_79', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_80 = self.__batch_normalization(2, 'batch_normalization_80', num_features=896, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_80 = self.__conv(2, name='conv2d_80', in_channels=896, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_81 = self.__batch_normalization(2, 'batch_normalization_81', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_81 = self.__conv(2, name='conv2d_81', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_82 = self.__batch_normalization(2, 'batch_normalization_82', num_features=928, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_82 = self.__conv(2, name='conv2d_82', in_channels=928, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_83 = self.__batch_normalization(2, 'batch_normalization_83', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_83 = self.__conv(2, name='conv2d_83', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_84 = self.__batch_normalization(2, 'batch_normalization_84', num_features=960, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_84 = self.__conv(2, name='conv2d_84', in_channels=960, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_85 = self.__batch_normalization(2, 'batch_normalization_85', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_85 = self.__conv(2, name='conv2d_85', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_86 = self.__batch_normalization(2, 'batch_normalization_86', num_features=992, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_86 = self.__conv(2, name='conv2d_86', in_channels=992, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_87 = self.__batch_normalization(2, 'batch_normalization_87', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_87 = self.__conv(2, name='conv2d_87', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_88 = self.__batch_normalization(2, 'batch_normalization_88', num_features=1024, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_88 = self.__conv(2, name='conv2d_88', in_channels=1024, out_channels=512, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_89 = self.__batch_normalization(2, 'batch_normalization_89', num_features=512, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_89 = self.__conv(2, name='conv2d_89', in_channels=512, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_90 = self.__batch_normalization(2, 'batch_normalization_90', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_90 = self.__conv(2, name='conv2d_90', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_91 = self.__batch_normalization(2, 'batch_normalization_91', num_features=544, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_91 = self.__conv(2, name='conv2d_91', in_channels=544, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_92 = self.__batch_normalization(2, 'batch_normalization_92', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_92 = self.__conv(2, name='conv2d_92', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_93 = self.__batch_normalization(2, 'batch_normalization_93', num_features=576, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_93 = self.__conv(2, name='conv2d_93', in_channels=576, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_94 = self.__batch_normalization(2, 'batch_normalization_94', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_94 = self.__conv(2, name='conv2d_94', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_95 = self.__batch_normalization(2, 'batch_normalization_95', num_features=608, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_95 = self.__conv(2, name='conv2d_95', in_channels=608, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_96 = self.__batch_normalization(2, 'batch_normalization_96', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_96 = self.__conv(2, name='conv2d_96', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_97 = self.__batch_normalization(2, 'batch_normalization_97', num_features=640, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_97 = self.__conv(2, name='conv2d_97', in_channels=640, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_98 = self.__batch_normalization(2, 'batch_normalization_98', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_98 = self.__conv(2, name='conv2d_98', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_99 = self.__batch_normalization(2, 'batch_normalization_99', num_features=672, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_99 = self.__conv(2, name='conv2d_99', in_channels=672, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_100 = self.__batch_normalization(2, 'batch_normalization_100', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_100 = self.__conv(2, name='conv2d_100', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_101 = self.__batch_normalization(2, 'batch_normalization_101', num_features=704, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_101 = self.__conv(2, name='conv2d_101', in_channels=704, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_102 = self.__batch_normalization(2, 'batch_normalization_102', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_102 = self.__conv(2, name='conv2d_102', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_103 = self.__batch_normalization(2, 'batch_normalization_103', num_features=736, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_103 = self.__conv(2, name='conv2d_103', in_channels=736, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_104 = self.__batch_normalization(2, 'batch_normalization_104', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_104 = self.__conv(2, name='conv2d_104', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_105 = self.__batch_normalization(2, 'batch_normalization_105', num_features=768, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_105 = self.__conv(2, name='conv2d_105', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_106 = self.__batch_normalization(2, 'batch_normalization_106', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_106 = self.__conv(2, name='conv2d_106', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_107 = self.__batch_normalization(2, 'batch_normalization_107', num_features=800, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_107 = self.__conv(2, name='conv2d_107', in_channels=800, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_108 = self.__batch_normalization(2, 'batch_normalization_108', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_108 = self.__conv(2, name='conv2d_108', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_109 = self.__batch_normalization(2, 'batch_normalization_109', num_features=832, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_109 = self.__conv(2, name='conv2d_109', in_channels=832, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_110 = self.__batch_normalization(2, 'batch_normalization_110', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_110 = self.__conv(2, name='conv2d_110', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_111 = self.__batch_normalization(2, 'batch_normalization_111', num_features=864, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_111 = self.__conv(2, name='conv2d_111', in_channels=864, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_112 = self.__batch_normalization(2, 'batch_normalization_112', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_112 = self.__conv(2, name='conv2d_112', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_113 = self.__batch_normalization(2, 'batch_normalization_113', num_features=896, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_113 = self.__conv(2, name='conv2d_113', in_channels=896, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_114 = self.__batch_normalization(2, 'batch_normalization_114', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_114 = self.__conv(2, name='conv2d_114', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_115 = self.__batch_normalization(2, 'batch_normalization_115', num_features=928, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_115 = self.__conv(2, name='conv2d_115', in_channels=928, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_116 = self.__batch_normalization(2, 'batch_normalization_116', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_116 = self.__conv(2, name='conv2d_116', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_117 = self.__batch_normalization(2, 'batch_normalization_117', num_features=960, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_117 = self.__conv(2, name='conv2d_117', in_channels=960, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_118 = self.__batch_normalization(2, 'batch_normalization_118', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_118 = self.__conv(2, name='conv2d_118', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_119 = self.__batch_normalization(2, 'batch_normalization_119', num_features=992, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_119 = self.__conv(2, name='conv2d_119', in_channels=992, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_120 = self.__batch_normalization(2, 'batch_normalization_120', num_features=128, eps=1.1000000085914508e-05, momentum=0.0)
        self.conv2d_120 = self.__conv(2, name='conv2d_120', in_channels=128, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_121 = self.__batch_normalization(2, 'batch_normalization_121', num_features=1024, eps=1.1000000085914508e-05, momentum=0.0)
        self.dense_1 = self.__dense(name = 'dense_1', in_features = 1024, out_features = 2, bias = True)

    def forward(self, x):
        conv2d_1_pad    = F.pad(x, (2, 3, 2, 3))
        conv2d_1        = self.conv2d_1(conv2d_1_pad)
        batch_normalization_1 = self.batch_normalization_1(conv2d_1)
        activation_1    = F.relu(batch_normalization_1)
        max_pooling2d_1_pad = F.pad(activation_1, (0, 1, 0, 1), value=float('-inf'))
        max_pooling2d_1 = F.max_pool2d(max_pooling2d_1_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)
        batch_normalization_2 = self.batch_normalization_2(max_pooling2d_1)
        activation_2    = F.relu(batch_normalization_2)
        conv2d_2        = self.conv2d_2(activation_2)
        batch_normalization_3 = self.batch_normalization_3(conv2d_2)
        activation_3    = F.relu(batch_normalization_3)
        conv2d_3_pad    = F.pad(activation_3, (1, 1, 1, 1))
        conv2d_3        = self.conv2d_3(conv2d_3_pad)
        concatenate_1   = torch.cat((max_pooling2d_1, conv2d_3), 1)
        batch_normalization_4 = self.batch_normalization_4(concatenate_1)
        activation_4    = F.relu(batch_normalization_4)
        conv2d_4        = self.conv2d_4(activation_4)
        batch_normalization_5 = self.batch_normalization_5(conv2d_4)
        activation_5    = F.relu(batch_normalization_5)
        conv2d_5_pad    = F.pad(activation_5, (1, 1, 1, 1))
        conv2d_5        = self.conv2d_5(conv2d_5_pad)
        concatenate_2   = torch.cat((concatenate_1, conv2d_5), 1)
        batch_normalization_6 = self.batch_normalization_6(concatenate_2)
        activation_6    = F.relu(batch_normalization_6)
        conv2d_6        = self.conv2d_6(activation_6)
        batch_normalization_7 = self.batch_normalization_7(conv2d_6)
        activation_7    = F.relu(batch_normalization_7)
        conv2d_7_pad    = F.pad(activation_7, (1, 1, 1, 1))
        conv2d_7        = self.conv2d_7(conv2d_7_pad)
        concatenate_3   = torch.cat((concatenate_2, conv2d_7), 1)
        batch_normalization_8 = self.batch_normalization_8(concatenate_3)
        activation_8    = F.relu(batch_normalization_8)
        conv2d_8        = self.conv2d_8(activation_8)
        batch_normalization_9 = self.batch_normalization_9(conv2d_8)
        activation_9    = F.relu(batch_normalization_9)
        conv2d_9_pad    = F.pad(activation_9, (1, 1, 1, 1))
        conv2d_9        = self.conv2d_9(conv2d_9_pad)
        concatenate_4   = torch.cat((concatenate_3, conv2d_9), 1)
        batch_normalization_10 = self.batch_normalization_10(concatenate_4)
        activation_10   = F.relu(batch_normalization_10)
        conv2d_10       = self.conv2d_10(activation_10)
        batch_normalization_11 = self.batch_normalization_11(conv2d_10)
        activation_11   = F.relu(batch_normalization_11)
        conv2d_11_pad   = F.pad(activation_11, (1, 1, 1, 1))
        conv2d_11       = self.conv2d_11(conv2d_11_pad)
        concatenate_5   = torch.cat((concatenate_4, conv2d_11), 1)
        batch_normalization_12 = self.batch_normalization_12(concatenate_5)
        activation_12   = F.relu(batch_normalization_12)
        conv2d_12       = self.conv2d_12(activation_12)
        batch_normalization_13 = self.batch_normalization_13(conv2d_12)
        activation_13   = F.relu(batch_normalization_13)
        conv2d_13_pad   = F.pad(activation_13, (1, 1, 1, 1))
        conv2d_13       = self.conv2d_13(conv2d_13_pad)
        concatenate_6   = torch.cat((concatenate_5, conv2d_13), 1)
        batch_normalization_14 = self.batch_normalization_14(concatenate_6)
        activation_14   = F.relu(batch_normalization_14)
        conv2d_14       = self.conv2d_14(activation_14)
        average_pooling2d_1 = F.avg_pool2d(conv2d_14, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=False)
        batch_normalization_15 = self.batch_normalization_15(average_pooling2d_1)
        activation_15   = F.relu(batch_normalization_15)
        conv2d_15       = self.conv2d_15(activation_15)
        batch_normalization_16 = self.batch_normalization_16(conv2d_15)
        activation_16   = F.relu(batch_normalization_16)
        conv2d_16_pad   = F.pad(activation_16, (1, 1, 1, 1))
        conv2d_16       = self.conv2d_16(conv2d_16_pad)
        concatenate_7   = torch.cat((average_pooling2d_1, conv2d_16), 1)
        batch_normalization_17 = self.batch_normalization_17(concatenate_7)
        activation_17   = F.relu(batch_normalization_17)
        conv2d_17       = self.conv2d_17(activation_17)
        batch_normalization_18 = self.batch_normalization_18(conv2d_17)
        activation_18   = F.relu(batch_normalization_18)
        conv2d_18_pad   = F.pad(activation_18, (1, 1, 1, 1))
        conv2d_18       = self.conv2d_18(conv2d_18_pad)
        concatenate_8   = torch.cat((concatenate_7, conv2d_18), 1)
        batch_normalization_19 = self.batch_normalization_19(concatenate_8)
        activation_19   = F.relu(batch_normalization_19)
        conv2d_19       = self.conv2d_19(activation_19)
        batch_normalization_20 = self.batch_normalization_20(conv2d_19)
        activation_20   = F.relu(batch_normalization_20)
        conv2d_20_pad   = F.pad(activation_20, (1, 1, 1, 1))
        conv2d_20       = self.conv2d_20(conv2d_20_pad)
        concatenate_9   = torch.cat((concatenate_8, conv2d_20), 1)
        batch_normalization_21 = self.batch_normalization_21(concatenate_9)
        activation_21   = F.relu(batch_normalization_21)
        conv2d_21       = self.conv2d_21(activation_21)
        batch_normalization_22 = self.batch_normalization_22(conv2d_21)
        activation_22   = F.relu(batch_normalization_22)
        conv2d_22_pad   = F.pad(activation_22, (1, 1, 1, 1))
        conv2d_22       = self.conv2d_22(conv2d_22_pad)
        concatenate_10  = torch.cat((concatenate_9, conv2d_22), 1)
        batch_normalization_23 = self.batch_normalization_23(concatenate_10)
        activation_23   = F.relu(batch_normalization_23)
        conv2d_23       = self.conv2d_23(activation_23)
        batch_normalization_24 = self.batch_normalization_24(conv2d_23)
        activation_24   = F.relu(batch_normalization_24)
        conv2d_24_pad   = F.pad(activation_24, (1, 1, 1, 1))
        conv2d_24       = self.conv2d_24(conv2d_24_pad)
        concatenate_11  = torch.cat((concatenate_10, conv2d_24), 1)
        batch_normalization_25 = self.batch_normalization_25(concatenate_11)
        activation_25   = F.relu(batch_normalization_25)
        conv2d_25       = self.conv2d_25(activation_25)
        batch_normalization_26 = self.batch_normalization_26(conv2d_25)
        activation_26   = F.relu(batch_normalization_26)
        conv2d_26_pad   = F.pad(activation_26, (1, 1, 1, 1))
        conv2d_26       = self.conv2d_26(conv2d_26_pad)
        concatenate_12  = torch.cat((concatenate_11, conv2d_26), 1)
        batch_normalization_27 = self.batch_normalization_27(concatenate_12)
        activation_27   = F.relu(batch_normalization_27)
        conv2d_27       = self.conv2d_27(activation_27)
        batch_normalization_28 = self.batch_normalization_28(conv2d_27)
        activation_28   = F.relu(batch_normalization_28)
        conv2d_28_pad   = F.pad(activation_28, (1, 1, 1, 1))
        conv2d_28       = self.conv2d_28(conv2d_28_pad)
        concatenate_13  = torch.cat((concatenate_12, conv2d_28), 1)
        batch_normalization_29 = self.batch_normalization_29(concatenate_13)
        activation_29   = F.relu(batch_normalization_29)
        conv2d_29       = self.conv2d_29(activation_29)
        batch_normalization_30 = self.batch_normalization_30(conv2d_29)
        activation_30   = F.relu(batch_normalization_30)
        conv2d_30_pad   = F.pad(activation_30, (1, 1, 1, 1))
        conv2d_30       = self.conv2d_30(conv2d_30_pad)
        concatenate_14  = torch.cat((concatenate_13, conv2d_30), 1)
        batch_normalization_31 = self.batch_normalization_31(concatenate_14)
        activation_31   = F.relu(batch_normalization_31)
        conv2d_31       = self.conv2d_31(activation_31)
        batch_normalization_32 = self.batch_normalization_32(conv2d_31)
        activation_32   = F.relu(batch_normalization_32)
        conv2d_32_pad   = F.pad(activation_32, (1, 1, 1, 1))
        conv2d_32       = self.conv2d_32(conv2d_32_pad)
        concatenate_15  = torch.cat((concatenate_14, conv2d_32), 1)
        batch_normalization_33 = self.batch_normalization_33(concatenate_15)
        activation_33   = F.relu(batch_normalization_33)
        conv2d_33       = self.conv2d_33(activation_33)
        batch_normalization_34 = self.batch_normalization_34(conv2d_33)
        activation_34   = F.relu(batch_normalization_34)
        conv2d_34_pad   = F.pad(activation_34, (1, 1, 1, 1))
        conv2d_34       = self.conv2d_34(conv2d_34_pad)
        concatenate_16  = torch.cat((concatenate_15, conv2d_34), 1)
        batch_normalization_35 = self.batch_normalization_35(concatenate_16)
        activation_35   = F.relu(batch_normalization_35)
        conv2d_35       = self.conv2d_35(activation_35)
        batch_normalization_36 = self.batch_normalization_36(conv2d_35)
        activation_36   = F.relu(batch_normalization_36)
        conv2d_36_pad   = F.pad(activation_36, (1, 1, 1, 1))
        conv2d_36       = self.conv2d_36(conv2d_36_pad)
        concatenate_17  = torch.cat((concatenate_16, conv2d_36), 1)
        batch_normalization_37 = self.batch_normalization_37(concatenate_17)
        activation_37   = F.relu(batch_normalization_37)
        conv2d_37       = self.conv2d_37(activation_37)
        batch_normalization_38 = self.batch_normalization_38(conv2d_37)
        activation_38   = F.relu(batch_normalization_38)
        conv2d_38_pad   = F.pad(activation_38, (1, 1, 1, 1))
        conv2d_38       = self.conv2d_38(conv2d_38_pad)
        concatenate_18  = torch.cat((concatenate_17, conv2d_38), 1)
        batch_normalization_39 = self.batch_normalization_39(concatenate_18)
        activation_39   = F.relu(batch_normalization_39)
        conv2d_39       = self.conv2d_39(activation_39)
        average_pooling2d_2 = F.avg_pool2d(conv2d_39, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=False)
        batch_normalization_40 = self.batch_normalization_40(average_pooling2d_2)
        activation_40   = F.relu(batch_normalization_40)
        conv2d_40       = self.conv2d_40(activation_40)
        batch_normalization_41 = self.batch_normalization_41(conv2d_40)
        activation_41   = F.relu(batch_normalization_41)
        conv2d_41_pad   = F.pad(activation_41, (1, 1, 1, 1))
        conv2d_41       = self.conv2d_41(conv2d_41_pad)
        concatenate_19  = torch.cat((average_pooling2d_2, conv2d_41), 1)
        batch_normalization_42 = self.batch_normalization_42(concatenate_19)
        activation_42   = F.relu(batch_normalization_42)
        conv2d_42       = self.conv2d_42(activation_42)
        batch_normalization_43 = self.batch_normalization_43(conv2d_42)
        activation_43   = F.relu(batch_normalization_43)
        conv2d_43_pad   = F.pad(activation_43, (1, 1, 1, 1))
        conv2d_43       = self.conv2d_43(conv2d_43_pad)
        concatenate_20  = torch.cat((concatenate_19, conv2d_43), 1)
        batch_normalization_44 = self.batch_normalization_44(concatenate_20)
        activation_44   = F.relu(batch_normalization_44)
        conv2d_44       = self.conv2d_44(activation_44)
        batch_normalization_45 = self.batch_normalization_45(conv2d_44)
        activation_45   = F.relu(batch_normalization_45)
        conv2d_45_pad   = F.pad(activation_45, (1, 1, 1, 1))
        conv2d_45       = self.conv2d_45(conv2d_45_pad)
        concatenate_21  = torch.cat((concatenate_20, conv2d_45), 1)
        batch_normalization_46 = self.batch_normalization_46(concatenate_21)
        activation_46   = F.relu(batch_normalization_46)
        conv2d_46       = self.conv2d_46(activation_46)
        batch_normalization_47 = self.batch_normalization_47(conv2d_46)
        activation_47   = F.relu(batch_normalization_47)
        conv2d_47_pad   = F.pad(activation_47, (1, 1, 1, 1))
        conv2d_47       = self.conv2d_47(conv2d_47_pad)
        concatenate_22  = torch.cat((concatenate_21, conv2d_47), 1)
        batch_normalization_48 = self.batch_normalization_48(concatenate_22)
        activation_48   = F.relu(batch_normalization_48)
        conv2d_48       = self.conv2d_48(activation_48)
        batch_normalization_49 = self.batch_normalization_49(conv2d_48)
        activation_49   = F.relu(batch_normalization_49)
        conv2d_49_pad   = F.pad(activation_49, (1, 1, 1, 1))
        conv2d_49       = self.conv2d_49(conv2d_49_pad)
        concatenate_23  = torch.cat((concatenate_22, conv2d_49), 1)
        batch_normalization_50 = self.batch_normalization_50(concatenate_23)
        activation_50   = F.relu(batch_normalization_50)
        conv2d_50       = self.conv2d_50(activation_50)
        batch_normalization_51 = self.batch_normalization_51(conv2d_50)
        activation_51   = F.relu(batch_normalization_51)
        conv2d_51_pad   = F.pad(activation_51, (1, 1, 1, 1))
        conv2d_51       = self.conv2d_51(conv2d_51_pad)
        concatenate_24  = torch.cat((concatenate_23, conv2d_51), 1)
        batch_normalization_52 = self.batch_normalization_52(concatenate_24)
        activation_52   = F.relu(batch_normalization_52)
        conv2d_52       = self.conv2d_52(activation_52)
        batch_normalization_53 = self.batch_normalization_53(conv2d_52)
        activation_53   = F.relu(batch_normalization_53)
        conv2d_53_pad   = F.pad(activation_53, (1, 1, 1, 1))
        conv2d_53       = self.conv2d_53(conv2d_53_pad)
        concatenate_25  = torch.cat((concatenate_24, conv2d_53), 1)
        batch_normalization_54 = self.batch_normalization_54(concatenate_25)
        activation_54   = F.relu(batch_normalization_54)
        conv2d_54       = self.conv2d_54(activation_54)
        batch_normalization_55 = self.batch_normalization_55(conv2d_54)
        activation_55   = F.relu(batch_normalization_55)
        conv2d_55_pad   = F.pad(activation_55, (1, 1, 1, 1))
        conv2d_55       = self.conv2d_55(conv2d_55_pad)
        concatenate_26  = torch.cat((concatenate_25, conv2d_55), 1)
        batch_normalization_56 = self.batch_normalization_56(concatenate_26)
        activation_56   = F.relu(batch_normalization_56)
        conv2d_56       = self.conv2d_56(activation_56)
        batch_normalization_57 = self.batch_normalization_57(conv2d_56)
        activation_57   = F.relu(batch_normalization_57)
        conv2d_57_pad   = F.pad(activation_57, (1, 1, 1, 1))
        conv2d_57       = self.conv2d_57(conv2d_57_pad)
        concatenate_27  = torch.cat((concatenate_26, conv2d_57), 1)
        batch_normalization_58 = self.batch_normalization_58(concatenate_27)
        activation_58   = F.relu(batch_normalization_58)
        conv2d_58       = self.conv2d_58(activation_58)
        batch_normalization_59 = self.batch_normalization_59(conv2d_58)
        activation_59   = F.relu(batch_normalization_59)
        conv2d_59_pad   = F.pad(activation_59, (1, 1, 1, 1))
        conv2d_59       = self.conv2d_59(conv2d_59_pad)
        concatenate_28  = torch.cat((concatenate_27, conv2d_59), 1)
        batch_normalization_60 = self.batch_normalization_60(concatenate_28)
        activation_60   = F.relu(batch_normalization_60)
        conv2d_60       = self.conv2d_60(activation_60)
        batch_normalization_61 = self.batch_normalization_61(conv2d_60)
        activation_61   = F.relu(batch_normalization_61)
        conv2d_61_pad   = F.pad(activation_61, (1, 1, 1, 1))
        conv2d_61       = self.conv2d_61(conv2d_61_pad)
        concatenate_29  = torch.cat((concatenate_28, conv2d_61), 1)
        batch_normalization_62 = self.batch_normalization_62(concatenate_29)
        activation_62   = F.relu(batch_normalization_62)
        conv2d_62       = self.conv2d_62(activation_62)
        batch_normalization_63 = self.batch_normalization_63(conv2d_62)
        activation_63   = F.relu(batch_normalization_63)
        conv2d_63_pad   = F.pad(activation_63, (1, 1, 1, 1))
        conv2d_63       = self.conv2d_63(conv2d_63_pad)
        concatenate_30  = torch.cat((concatenate_29, conv2d_63), 1)
        batch_normalization_64 = self.batch_normalization_64(concatenate_30)
        activation_64   = F.relu(batch_normalization_64)
        conv2d_64       = self.conv2d_64(activation_64)
        batch_normalization_65 = self.batch_normalization_65(conv2d_64)
        activation_65   = F.relu(batch_normalization_65)
        conv2d_65_pad   = F.pad(activation_65, (1, 1, 1, 1))
        conv2d_65       = self.conv2d_65(conv2d_65_pad)
        concatenate_31  = torch.cat((concatenate_30, conv2d_65), 1)
        batch_normalization_66 = self.batch_normalization_66(concatenate_31)
        activation_66   = F.relu(batch_normalization_66)
        conv2d_66       = self.conv2d_66(activation_66)
        batch_normalization_67 = self.batch_normalization_67(conv2d_66)
        activation_67   = F.relu(batch_normalization_67)
        conv2d_67_pad   = F.pad(activation_67, (1, 1, 1, 1))
        conv2d_67       = self.conv2d_67(conv2d_67_pad)
        concatenate_32  = torch.cat((concatenate_31, conv2d_67), 1)
        batch_normalization_68 = self.batch_normalization_68(concatenate_32)
        activation_68   = F.relu(batch_normalization_68)
        conv2d_68       = self.conv2d_68(activation_68)
        batch_normalization_69 = self.batch_normalization_69(conv2d_68)
        activation_69   = F.relu(batch_normalization_69)
        conv2d_69_pad   = F.pad(activation_69, (1, 1, 1, 1))
        conv2d_69       = self.conv2d_69(conv2d_69_pad)
        concatenate_33  = torch.cat((concatenate_32, conv2d_69), 1)
        batch_normalization_70 = self.batch_normalization_70(concatenate_33)
        activation_70   = F.relu(batch_normalization_70)
        conv2d_70       = self.conv2d_70(activation_70)
        batch_normalization_71 = self.batch_normalization_71(conv2d_70)
        activation_71   = F.relu(batch_normalization_71)
        conv2d_71_pad   = F.pad(activation_71, (1, 1, 1, 1))
        conv2d_71       = self.conv2d_71(conv2d_71_pad)
        concatenate_34  = torch.cat((concatenate_33, conv2d_71), 1)
        batch_normalization_72 = self.batch_normalization_72(concatenate_34)
        activation_72   = F.relu(batch_normalization_72)
        conv2d_72       = self.conv2d_72(activation_72)
        batch_normalization_73 = self.batch_normalization_73(conv2d_72)
        activation_73   = F.relu(batch_normalization_73)
        conv2d_73_pad   = F.pad(activation_73, (1, 1, 1, 1))
        conv2d_73       = self.conv2d_73(conv2d_73_pad)
        concatenate_35  = torch.cat((concatenate_34, conv2d_73), 1)
        batch_normalization_74 = self.batch_normalization_74(concatenate_35)
        activation_74   = F.relu(batch_normalization_74)
        conv2d_74       = self.conv2d_74(activation_74)
        batch_normalization_75 = self.batch_normalization_75(conv2d_74)
        activation_75   = F.relu(batch_normalization_75)
        conv2d_75_pad   = F.pad(activation_75, (1, 1, 1, 1))
        conv2d_75       = self.conv2d_75(conv2d_75_pad)
        concatenate_36  = torch.cat((concatenate_35, conv2d_75), 1)
        batch_normalization_76 = self.batch_normalization_76(concatenate_36)
        activation_76   = F.relu(batch_normalization_76)
        conv2d_76       = self.conv2d_76(activation_76)
        batch_normalization_77 = self.batch_normalization_77(conv2d_76)
        activation_77   = F.relu(batch_normalization_77)
        conv2d_77_pad   = F.pad(activation_77, (1, 1, 1, 1))
        conv2d_77       = self.conv2d_77(conv2d_77_pad)
        concatenate_37  = torch.cat((concatenate_36, conv2d_77), 1)
        batch_normalization_78 = self.batch_normalization_78(concatenate_37)
        activation_78   = F.relu(batch_normalization_78)
        conv2d_78       = self.conv2d_78(activation_78)
        batch_normalization_79 = self.batch_normalization_79(conv2d_78)
        activation_79   = F.relu(batch_normalization_79)
        conv2d_79_pad   = F.pad(activation_79, (1, 1, 1, 1))
        conv2d_79       = self.conv2d_79(conv2d_79_pad)
        concatenate_38  = torch.cat((concatenate_37, conv2d_79), 1)
        batch_normalization_80 = self.batch_normalization_80(concatenate_38)
        activation_80   = F.relu(batch_normalization_80)
        conv2d_80       = self.conv2d_80(activation_80)
        batch_normalization_81 = self.batch_normalization_81(conv2d_80)
        activation_81   = F.relu(batch_normalization_81)
        conv2d_81_pad   = F.pad(activation_81, (1, 1, 1, 1))
        conv2d_81       = self.conv2d_81(conv2d_81_pad)
        concatenate_39  = torch.cat((concatenate_38, conv2d_81), 1)
        batch_normalization_82 = self.batch_normalization_82(concatenate_39)
        activation_82   = F.relu(batch_normalization_82)
        conv2d_82       = self.conv2d_82(activation_82)
        batch_normalization_83 = self.batch_normalization_83(conv2d_82)
        activation_83   = F.relu(batch_normalization_83)
        conv2d_83_pad   = F.pad(activation_83, (1, 1, 1, 1))
        conv2d_83       = self.conv2d_83(conv2d_83_pad)
        concatenate_40  = torch.cat((concatenate_39, conv2d_83), 1)
        batch_normalization_84 = self.batch_normalization_84(concatenate_40)
        activation_84   = F.relu(batch_normalization_84)
        conv2d_84       = self.conv2d_84(activation_84)
        batch_normalization_85 = self.batch_normalization_85(conv2d_84)
        activation_85   = F.relu(batch_normalization_85)
        conv2d_85_pad   = F.pad(activation_85, (1, 1, 1, 1))
        conv2d_85       = self.conv2d_85(conv2d_85_pad)
        concatenate_41  = torch.cat((concatenate_40, conv2d_85), 1)
        batch_normalization_86 = self.batch_normalization_86(concatenate_41)
        activation_86   = F.relu(batch_normalization_86)
        conv2d_86       = self.conv2d_86(activation_86)
        batch_normalization_87 = self.batch_normalization_87(conv2d_86)
        activation_87   = F.relu(batch_normalization_87)
        conv2d_87_pad   = F.pad(activation_87, (1, 1, 1, 1))
        conv2d_87       = self.conv2d_87(conv2d_87_pad)
        concatenate_42  = torch.cat((concatenate_41, conv2d_87), 1)
        batch_normalization_88 = self.batch_normalization_88(concatenate_42)
        activation_88   = F.relu(batch_normalization_88)
        conv2d_88       = self.conv2d_88(activation_88)
        average_pooling2d_3 = F.avg_pool2d(conv2d_88, kernel_size=(2, 2), stride=(2, 2), padding=(0,), ceil_mode=False)
        batch_normalization_89 = self.batch_normalization_89(average_pooling2d_3)
        activation_89   = F.relu(batch_normalization_89)
        conv2d_89       = self.conv2d_89(activation_89)
        batch_normalization_90 = self.batch_normalization_90(conv2d_89)
        activation_90   = F.relu(batch_normalization_90)
        conv2d_90_pad   = F.pad(activation_90, (1, 1, 1, 1))
        conv2d_90       = self.conv2d_90(conv2d_90_pad)
        concatenate_43  = torch.cat((average_pooling2d_3, conv2d_90), 1)
        batch_normalization_91 = self.batch_normalization_91(concatenate_43)
        activation_91   = F.relu(batch_normalization_91)
        conv2d_91       = self.conv2d_91(activation_91)
        batch_normalization_92 = self.batch_normalization_92(conv2d_91)
        activation_92   = F.relu(batch_normalization_92)
        conv2d_92_pad   = F.pad(activation_92, (1, 1, 1, 1))
        conv2d_92       = self.conv2d_92(conv2d_92_pad)
        concatenate_44  = torch.cat((concatenate_43, conv2d_92), 1)
        batch_normalization_93 = self.batch_normalization_93(concatenate_44)
        activation_93   = F.relu(batch_normalization_93)
        conv2d_93       = self.conv2d_93(activation_93)
        batch_normalization_94 = self.batch_normalization_94(conv2d_93)
        activation_94   = F.relu(batch_normalization_94)
        conv2d_94_pad   = F.pad(activation_94, (1, 1, 1, 1))
        conv2d_94       = self.conv2d_94(conv2d_94_pad)
        concatenate_45  = torch.cat((concatenate_44, conv2d_94), 1)
        batch_normalization_95 = self.batch_normalization_95(concatenate_45)
        activation_95   = F.relu(batch_normalization_95)
        conv2d_95       = self.conv2d_95(activation_95)
        batch_normalization_96 = self.batch_normalization_96(conv2d_95)
        activation_96   = F.relu(batch_normalization_96)
        conv2d_96_pad   = F.pad(activation_96, (1, 1, 1, 1))
        conv2d_96       = self.conv2d_96(conv2d_96_pad)
        concatenate_46  = torch.cat((concatenate_45, conv2d_96), 1)
        batch_normalization_97 = self.batch_normalization_97(concatenate_46)
        activation_97   = F.relu(batch_normalization_97)
        conv2d_97       = self.conv2d_97(activation_97)
        batch_normalization_98 = self.batch_normalization_98(conv2d_97)
        activation_98   = F.relu(batch_normalization_98)
        conv2d_98_pad   = F.pad(activation_98, (1, 1, 1, 1))
        conv2d_98       = self.conv2d_98(conv2d_98_pad)
        concatenate_47  = torch.cat((concatenate_46, conv2d_98), 1)
        batch_normalization_99 = self.batch_normalization_99(concatenate_47)
        activation_99   = F.relu(batch_normalization_99)
        conv2d_99       = self.conv2d_99(activation_99)
        batch_normalization_100 = self.batch_normalization_100(conv2d_99)
        activation_100  = F.relu(batch_normalization_100)
        conv2d_100_pad  = F.pad(activation_100, (1, 1, 1, 1))
        conv2d_100      = self.conv2d_100(conv2d_100_pad)
        concatenate_48  = torch.cat((concatenate_47, conv2d_100), 1)
        batch_normalization_101 = self.batch_normalization_101(concatenate_48)
        activation_101  = F.relu(batch_normalization_101)
        conv2d_101      = self.conv2d_101(activation_101)
        batch_normalization_102 = self.batch_normalization_102(conv2d_101)
        activation_102  = F.relu(batch_normalization_102)
        conv2d_102_pad  = F.pad(activation_102, (1, 1, 1, 1))
        conv2d_102      = self.conv2d_102(conv2d_102_pad)
        concatenate_49  = torch.cat((concatenate_48, conv2d_102), 1)
        batch_normalization_103 = self.batch_normalization_103(concatenate_49)
        activation_103  = F.relu(batch_normalization_103)
        conv2d_103      = self.conv2d_103(activation_103)
        batch_normalization_104 = self.batch_normalization_104(conv2d_103)
        activation_104  = F.relu(batch_normalization_104)
        conv2d_104_pad  = F.pad(activation_104, (1, 1, 1, 1))
        conv2d_104      = self.conv2d_104(conv2d_104_pad)
        concatenate_50  = torch.cat((concatenate_49, conv2d_104), 1)
        batch_normalization_105 = self.batch_normalization_105(concatenate_50)
        activation_105  = F.relu(batch_normalization_105)
        conv2d_105      = self.conv2d_105(activation_105)
        batch_normalization_106 = self.batch_normalization_106(conv2d_105)
        activation_106  = F.relu(batch_normalization_106)
        conv2d_106_pad  = F.pad(activation_106, (1, 1, 1, 1))
        conv2d_106      = self.conv2d_106(conv2d_106_pad)
        concatenate_51  = torch.cat((concatenate_50, conv2d_106), 1)
        batch_normalization_107 = self.batch_normalization_107(concatenate_51)
        activation_107  = F.relu(batch_normalization_107)
        conv2d_107      = self.conv2d_107(activation_107)
        batch_normalization_108 = self.batch_normalization_108(conv2d_107)
        activation_108  = F.relu(batch_normalization_108)
        conv2d_108_pad  = F.pad(activation_108, (1, 1, 1, 1))
        conv2d_108      = self.conv2d_108(conv2d_108_pad)
        concatenate_52  = torch.cat((concatenate_51, conv2d_108), 1)
        batch_normalization_109 = self.batch_normalization_109(concatenate_52)
        activation_109  = F.relu(batch_normalization_109)
        conv2d_109      = self.conv2d_109(activation_109)
        batch_normalization_110 = self.batch_normalization_110(conv2d_109)
        activation_110  = F.relu(batch_normalization_110)
        conv2d_110_pad  = F.pad(activation_110, (1, 1, 1, 1))
        conv2d_110      = self.conv2d_110(conv2d_110_pad)
        concatenate_53  = torch.cat((concatenate_52, conv2d_110), 1)
        batch_normalization_111 = self.batch_normalization_111(concatenate_53)
        activation_111  = F.relu(batch_normalization_111)
        conv2d_111      = self.conv2d_111(activation_111)
        batch_normalization_112 = self.batch_normalization_112(conv2d_111)
        activation_112  = F.relu(batch_normalization_112)
        conv2d_112_pad  = F.pad(activation_112, (1, 1, 1, 1))
        conv2d_112      = self.conv2d_112(conv2d_112_pad)
        concatenate_54  = torch.cat((concatenate_53, conv2d_112), 1)
        batch_normalization_113 = self.batch_normalization_113(concatenate_54)
        activation_113  = F.relu(batch_normalization_113)
        conv2d_113      = self.conv2d_113(activation_113)
        batch_normalization_114 = self.batch_normalization_114(conv2d_113)
        activation_114  = F.relu(batch_normalization_114)
        conv2d_114_pad  = F.pad(activation_114, (1, 1, 1, 1))
        conv2d_114      = self.conv2d_114(conv2d_114_pad)
        concatenate_55  = torch.cat((concatenate_54, conv2d_114), 1)
        batch_normalization_115 = self.batch_normalization_115(concatenate_55)
        activation_115  = F.relu(batch_normalization_115)
        conv2d_115      = self.conv2d_115(activation_115)
        batch_normalization_116 = self.batch_normalization_116(conv2d_115)
        activation_116  = F.relu(batch_normalization_116)
        conv2d_116_pad  = F.pad(activation_116, (1, 1, 1, 1))
        conv2d_116      = self.conv2d_116(conv2d_116_pad)
        concatenate_56  = torch.cat((concatenate_55, conv2d_116), 1)
        batch_normalization_117 = self.batch_normalization_117(concatenate_56)
        activation_117  = F.relu(batch_normalization_117)
        conv2d_117      = self.conv2d_117(activation_117)
        batch_normalization_118 = self.batch_normalization_118(conv2d_117)
        activation_118  = F.relu(batch_normalization_118)
        conv2d_118_pad  = F.pad(activation_118, (1, 1, 1, 1))
        conv2d_118      = self.conv2d_118(conv2d_118_pad)
        concatenate_57  = torch.cat((concatenate_56, conv2d_118), 1)
        batch_normalization_119 = self.batch_normalization_119(concatenate_57)
        activation_119  = F.relu(batch_normalization_119)
        conv2d_119      = self.conv2d_119(activation_119)
        batch_normalization_120 = self.batch_normalization_120(conv2d_119)
        activation_120  = F.relu(batch_normalization_120)
        conv2d_120_pad  = F.pad(activation_120, (1, 1, 1, 1))
        conv2d_120      = self.conv2d_120(conv2d_120_pad)
        concatenate_58  = torch.cat((concatenate_57, conv2d_120), 1)
        batch_normalization_121 = self.batch_normalization_121(concatenate_58)
        activation_121  = F.relu(batch_normalization_121)
        global_average_pooling2d_1 = F.avg_pool2d(input = activation_121, kernel_size = activation_121.size()[2:])
        global_average_pooling2d_1_flatten = global_average_pooling2d_1.view(global_average_pooling2d_1.size(0), -1)
        dense_1         = self.dense_1(global_average_pooling2d_1_flatten)
        # dense_1_activation = F.softmax(dense_1)
        return dense_1


    @staticmethod
    def __dense(name, **kwargs):
        layer = nn.Linear(**kwargs)
        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

    @staticmethod
    def __batch_normalization(dim, name, **kwargs):
        if   dim == 1:  layer = nn.BatchNorm1d(**kwargs)
        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)
        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)
        else:           raise NotImplementedError()

        if 'scale' in __weights_dict[name]:
            layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['scale']))
        else:
            layer.weight.data.fill_(1)

        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        else:
            layer.bias.data.fill_(0)

        layer.state_dict()['running_mean'].copy_(torch.from_numpy(__weights_dict[name]['mean']))
        layer.state_dict()['running_var'].copy_(torch.from_numpy(__weights_dict[name]['var']))
        return layer

    @staticmethod
    def __conv(dim, name, **kwargs):
        if   dim == 1:  layer = nn.Conv1d(**kwargs)
        elif dim == 2:  layer = nn.Conv2d(**kwargs)
        elif dim == 3:  layer = nn.Conv3d(**kwargs)
        else:           raise NotImplementedError()

        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

